{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Geneartive-Adversarial-Networks.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ricvolpe/ml-essentials/blob/master/papers/Geneartive_Adversarial_Networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "EKWebgWyX7yf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Machine Learning Essentials: Generative Adversarial Networks\n",
        "---\n",
        "\n",
        "Generative Adversarial Networks (GAN) are one, if not the, most interesting innovations in Artificial Intelligence in the last 10 years. Yann LeCun, one of the fathers of back-propagation, the core algorithm behind Deep Neural Networks went as far as saying that they are “the coolest idea in deep learning in the last 20 years.” \n",
        "\n",
        "Up until the emergence of GANs, all most impressive results in Artificial Intelligence and Deep Learning were associated with *discriminative* models, that is, models that given a data input can associate a meta-data output to the input, such as identifying an animal type in a picture or the text corresponding to a audio wave. GANs, very differently, are *generative* models, that is, given a noise input, the create something out of this noise.\n",
        "\n",
        "In this **Machine Learning Essentials** notebook, I share my understandings, notes and reflecltion on replicating the very first GAN developed as describe by, the now cornerstone of machine learning, paper *Generative Adversarial Nets* written by Ian Goodfellow, Yoshua Bengio, Aaron Courville and others in 2014."
      ]
    },
    {
      "metadata": {
        "id": "Orq-nOjXMzjC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Original Code and CPUs\n",
        "\n",
        "At first, I tried to fork and replicate the original source code provided with the GAN paper at [this GitHub lik](https://github.com/goodfeli/adversarial). However, the code has been un-maintained for few years and machine learning repositories become legacy extremely quickly these days. The code is largely built on the now un-maintained librarly *PyLearn2* (originally developed by some of the same authors of the paper). After substantial tweaking and re-built of all dependecies in other to find the exact versions of all packages that would enable the code to run, I finally managed it, watching my first local GAN running with some satisfaction.\n",
        "\n",
        "Only then I remembered that I had no GPU on my local machine. Collecting the training results when my computer was lameting overheating, my low expecetations were confirmed by the visualisation below:\n",
        "\n",
        "![attempt-at-replicating-results-on-CPU](https://docs.google.com/uc?export=download&id=1-rg06sWwauXKesjcNjYxPM9Y-_GiiifQ)\n",
        "\n",
        "Intriguide by the details of the paper and unsatisfied with my first replica, I turned to Google Collaborative, which offers Jupyter Notebooks with available GPU and TPU runtimes. However, as I realized that was not worth to perform all the tweaks and library installations to get the un-maintained original code to work on a Colab Notebook, I quickly found more modern [Tensorflow](https://towardsdatascience.com/generative-adversarial-networks-using-tensorflow-c8f4518406df) and [Keras](https://github.com/eriklindernoren/Keras-GAN) re-implementations of GANs."
      ]
    },
    {
      "metadata": {
        "id": "zd_ACR1h-mIe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Theory, Keras and GPUs \n",
        "\n",
        "\n",
        "Before GANs, most work on deep generative models focused on models that provided a parametric specification of a probability distribution function. However, such models, had intractable likelihood functions and required approximations. GANs are also often confused with Adversarial Examples. These are not generative models per se, but only show that network can discriminate differently objects that appears very similar to us, confirming the challenge of modelling multi-dimensional distributions.\n",
        "\n",
        "In a nutshell, Generative Adversarial Networks are made of two multilayer perceptrons: G the generator and D the discriminator. G captures the data distribution, while D tries to tell apart if something was coming from the original data or was generated by G. GANs have a theoretical unique solution where G replicates perfectly the data distribution and D assigns equal probably of being it from G or from data to any example. Both G and D are trained with back propagation, thus, no approximate inference or Markov chains are necessary. \n",
        "\n",
        "Formally, the key elements of a GAN are:\n",
        "\n",
        "![key-elements](https://docs.google.com/uc?export=download&id=1Gcm7uw5TOmXa1NzOzwjqpxAzk-qnoO7I)\n",
        "\n",
        "While we familiarise with them, let us also start importing all necessary packages required for our paper replication. As the paper provided samples and results for re-generative the famous MNIST handwritten digit data, we will also load this dataset."
      ]
    },
    {
      "metadata": {
        "id": "XmyjBT_cM__p",
        "colab_type": "code",
        "outputId": "c04207db-3bff-40b0-a48d-0c20d2c9b3bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function, division\n",
        "\n",
        "from keras.datasets import mnist\n",
        "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
        "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
        "from keras.models import Sequential, Model\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import sys\n",
        "\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ddlgd8w_CpAU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The generator model (G) take noise as inputs and generate a new image out of it. The generator has the goal of minimizing the number of times in which the discriminator correctly understand that its output is fake (i.e. being caught). That is, it is induced to reproduce exactly the data distribution. While in the original paper the Generator network uses Maxout layers, these are currently not available in Keras and the model below uses batch normalisation and leaky ReLU instead."
      ]
    },
    {
      "metadata": {
        "id": "c1R98wgANESQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def Generator(latent_dim, out_shape):\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Dense(1200, input_dim=latent_dim, activation='relu'))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(Dense(512))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(Dense(1024))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(Dense(np.prod(out_shape), activation='tanh'))\n",
        "    model.add(Reshape(out_shape))\n",
        "    \n",
        "    print('Generator Model')\n",
        "    model.summary()\n",
        "\n",
        "    noise = Input(shape=(latent_dim,))\n",
        "    img = model(noise)\n",
        "\n",
        "    return Model(noise, img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WuElajSWDKta",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The discriminator model D, which is a simpler network, has the goal of outputting 1 for every example drawn from the real data and do not incurring in cost when outputting 1 for an example coming from the generator."
      ]
    },
    {
      "metadata": {
        "id": "MD96K_agNTPB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def Discriminator(in_shape):\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Flatten(input_shape=in_shape))\n",
        "    model.add(Dense(512))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Dense(256))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    \n",
        "    print('Discriminator Model')\n",
        "    model.summary()\n",
        "\n",
        "    inp = Input(shape=in_shape)\n",
        "    validity = model(inp)\n",
        "\n",
        "    return Model(inp, validity)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8a6RXEr_DRTt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Combining the objective functions of both models, we obtain a minmax game in the form expanded below:\n",
        "\n",
        "![min-max](https://docs.google.com/uc?export=download&id=1QAxJ_h8_TNIdvJUItrqlrUKTkHhkIOqM)\n",
        "\n",
        "The authors prove in an elegan way that such game has a global optimum where the Generator network replicates the original distribution of the data. The steps below summarise the proof:\n",
        "\n",
        "![theoretical-proof](https://docs.google.com/uc?export=download&id=1b7Rb11N3dfG_OSBzsq5J2C14aLP5LKAA)\n",
        "\n",
        "In practic, the authors define a training algorithm - alike the one coded below - who lead G and D to converge to the above global optimum, which is further proved in paper.\n",
        "\n",
        "![theoretical-proof](https://docs.google.com/uc?export=download&id=1iwM4WMaaXzKuTWORigGFMs_CfCXQS-Kd)\n",
        "\n",
        "A very important caveat that the authors make is that in practice, adversarial nets represent a limited family of probability distributions via the function G(z; θ_g), and they optimize the θ parameters rather than probablity distribution itself, so the proofs do not fully apply to them. However, the excellent performance of multilayer perceptrons in practice suggests that they are a reasonable model to use despite their lack of theoretical guarantees."
      ]
    },
    {
      "metadata": {
        "id": "L25ldYhwNiD_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(data, latent_dim, generator, discriminator, combined, epochs, batch_size=128):\n",
        "\n",
        "    # Rescale -1 to 1\n",
        "    data = data / 127.5 - 1.\n",
        "    data = np.expand_dims(data, axis=3)\n",
        "\n",
        "    # Adversarial ground truths\n",
        "    valid = np.ones((batch_size, 1))\n",
        "    fake = np.zeros((batch_size, 1))\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        # ----- Train Discriminator\n",
        "        # Select a random batch of images\n",
        "        idx = np.random.randint(0, data.shape[0], batch_size)\n",
        "        imgs = data[idx]\n",
        "        noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
        "\n",
        "        # Generate a batch of new images\n",
        "        gen_imgs = generator.predict(noise)\n",
        "        \n",
        "        # Train the discriminator\n",
        "        d_loss_real = discriminator.train_on_batch(imgs, valid)\n",
        "        d_loss_fake = discriminator.train_on_batch(gen_imgs, fake)\n",
        "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "        \n",
        "        # ----- Train Generator\n",
        "        noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
        "\n",
        "        # Train the generator (to have the discriminator label samples as valid)\n",
        "        g_loss = combined.train_on_batch(noise, valid)\n",
        "\n",
        "        # Plot the progress\n",
        "        print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % \n",
        "               (epoch, d_loss[0], 100*d_loss[1], g_loss))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rCcYiqQmFDuY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "After having defined the training algorithm we can now define a function that queries it for new samples and show them to us in a human comprehensive way, so that we ourselves can assess if the generative model is qualitately performing well."
      ]
    },
    {
      "metadata": {
        "id": "pGw_Y91ZOgws",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def sample(latent_dim, generator):\n",
        "    \n",
        "    noise = np.random.normal(0, 1, (1, latent_dim))\n",
        "    gen_img = generator.predict(np.random.normal(0, 1, (1, latent_dim)))\n",
        "\n",
        "    # Rescale 0 - 1\n",
        "    gen_img = 0.5 * gen_img + 0.5\n",
        "    \n",
        "    # Plot\n",
        "    plt.imshow(gen_img[0, :,:,0], cmap='copper')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4g6Hjht8FVPU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We are not ready to define all the required paramenters (such as the input and output shapes and the gradient optimiser) compile and run our Keras models."
      ]
    },
    {
      "metadata": {
        "id": "S1ktLe-FPJFw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Set up dimensions\n",
        "rows = 28\n",
        "cols = 28\n",
        "channels = 1\n",
        "img_shape = (rows, cols, channels)\n",
        "latent_dim = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U8z9J5_gPW1d",
        "colab_type": "code",
        "outputId": "e97a3b24-8008-4eba-f32b-56d3e19326e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1166
        }
      },
      "cell_type": "code",
      "source": [
        "# Set up models\n",
        "optimizer = Adam(0.0002, 0.5)\n",
        "\n",
        "D = Discriminator(img_shape)\n",
        "D.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "G = Generator(latent_dim, img_shape)\n",
        "# The generator takes noise as input and generates imgs\n",
        "z = Input(shape=(latent_dim,))\n",
        "img = G(z)\n",
        "\n",
        "D.trainable = False # For the combined model we will only train the generator\n",
        "# The discriminator takes generated images as input and determines validity\n",
        "validity = D(img)\n",
        "\n",
        "# The combined model  (stacked generator and discriminator)\n",
        "# Trains the generator to fool the discriminator\n",
        "combined = Model(z, validity)\n",
        "print('Combined Model')\n",
        "combined.summary()\n",
        "combined.compile(loss='binary_crossentropy', optimizer=optimizer)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "Discriminator Model\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_1 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)    (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)    (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 533,505\n",
            "Trainable params: 533,505\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Generator Model\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_4 (Dense)              (None, 1200)              121200    \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 1200)              4800      \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 512)               614912    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)    (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1024)              525312    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)    (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 1024)              4096      \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 784)               803600    \n",
            "_________________________________________________________________\n",
            "reshape_1 (Reshape)          (None, 28, 28, 1)         0         \n",
            "=================================================================\n",
            "Total params: 2,075,968\n",
            "Trainable params: 2,070,496\n",
            "Non-trainable params: 5,472\n",
            "_________________________________________________________________\n",
            "Combined Model\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "model_2 (Model)              (None, 28, 28, 1)         2075968   \n",
            "_________________________________________________________________\n",
            "model_1 (Model)              (None, 1)                 533505    \n",
            "=================================================================\n",
            "Total params: 2,609,473\n",
            "Trainable params: 2,070,496\n",
            "Non-trainable params: 538,977\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bAE2Bgx5Fh47",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let us now train the model on the MNIST training data. Sadly I experienced issues when running the Collaborative Notebook for longer than 10000 epochs, thus, this was the maximum length I could train this GAN replica for."
      ]
    },
    {
      "metadata": {
        "id": "r2rpM_38QsTN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "(X_train, _), (X_test, _) = mnist.load_data()\n",
        "\n",
        "# Train combined model\n",
        "train(X_train, 100, G, D, combined, epochs=10000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Nbh_62HCF0fo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We can now generate few samples. We can see that, although the low number of epochs and relative fast training, generated samples resemble original numbers fairly well!"
      ]
    },
    {
      "metadata": {
        "id": "cSwmR_tSSb0k",
        "colab_type": "code",
        "outputId": "48428c5e-fba2-482e-9ee5-58697c04c581",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "cell_type": "code",
      "source": [
        "sample(100, G)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "K8wNSZnNGC77",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Problematic Bonus: Parzen Window Estimation\n",
        "\n",
        "To fully replicate the original GAN work, I aimed at reproducing the experimental evaluations provided in the paper as well. The authors evaluate their models using a by fitting a Gaussian Parzen window to the samples generated with G and reporting the log-likelihood of the original data under this distribution. \n",
        "\n",
        "The code provided below generates one hundres samples from the trained Generator and then evaluates them using a Gaussian Parzen window. However, for lack of training or perhaps my mistakes in the re-implementation of the window function results are singificantly different from the original ones provided in the paper. As my understanding of machine learning essentials matures, I will further investigate this discrepancy."
      ]
    },
    {
      "metadata": {
        "id": "q1NWTfTQHRh9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "samples = np.array([G.predict(np.random.normal(0, 1, (1, 100))) for x in range(len(X_test))])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YtqSH362HttB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def parzen(X, sigma):\n",
        "\n",
        "    def parzen_window(x):\n",
        "        mu = X\n",
        "        a = (x.reshape(x.shape[0], 1, x.shape[1]) - mu.reshape(1, mu.shape[0], mu.shape[1])) / sigma\n",
        "        est = (1 / sigma * np.sqrt(np.pi * 2)) * (np.exp(-0.5*(a**2).sum(2)))\n",
        "        return est\n",
        "    return parzen_window\n",
        "\n",
        "def batch_mean_of_densities(n_batches, pz_win, X, indexes):\n",
        "    times = []\n",
        "    nlls = []\n",
        "    for i in range(n_batches):\n",
        "        begin = time.time()\n",
        "        nll = pz_win(X[indexes[i::n_batches]])\n",
        "        end = time.time()\n",
        "        nlls.extend(nll)\n",
        "        times.append(end-begin)\n",
        "\n",
        "        if i % 10 == 0:\n",
        "            print (i, np.mean(times), np.mean(nlls))\n",
        "    return nlls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-V5yxVXpKMPz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "samples = samples.reshape((samples.shape[0], np.prod(samples.shape[1:])))\n",
        "pz_win = parzen(samples, 0.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oDyi_l7-KQiN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_test_norm = X_test / 127.5 - 1.\n",
        "X_test_norm = X_test_norm.reshape((X_test_norm.shape[0], np.prod(X_test_norm.shape[1:])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4tVuOi8xN-Pb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "inds = range(X_test_norm.shape[0])\n",
        "n_batches = int(np.ceil(float(len(inds)) / 10))\n",
        "nlls = batch_mean_of_densities(n_batches, pz_win, X_test_norm, inds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "82kfKWirQNRs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ll = np.array(nlls)\n",
        "se = ll.std() / np.sqrt(X_test_norm.shape[0])\n",
        "print(ll.mean(), se)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "heJRL28-Zz_j",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## References\n",
        "\n",
        "- https://kaushikghose.wordpress.com/2013/10/23/parzen-windows-for-estimating-distributions/\n",
        "- https://www.projectrhea.org/rhea/index.php/Parzen_Window_Density_Estimation\n",
        "- http://www.personal.reading.ac.uk/~sis01xh/teaching/CY2D2/Pattern2.pdf\n",
        "- https://towardsdatascience.com/generative-adversarial-networks-using-tensorflow-c8f4518406df .\n",
        "- https://github.com/eriklindernoren/Keras-GAN\n"
      ]
    }
  ]
}